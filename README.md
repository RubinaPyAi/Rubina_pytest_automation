Pytest Framework: Setup, Execution, and Git Integration

Overview

This repository contains automated test cases written using Pytest. It covers various aspects of test execution, including test parameterization, skipping tests, failure handling, and parallel execution. Additionally, it includes Git and GitHub integration to manage and version control test scripts efficiently.


---

Installation

Ensure you have Python installed, then install pytest using:

pip install pytest


---

Project Structure

The repository includes the following files and directories:

rubina_pyfiles_automation/
│── _pycache_/                 # Cache files generated by Python  
│── .pytest_cache/             # Pytest cache directory  
│── conftest.py                # Configuration file for fixtures  
│── func2.py                   # Python function for testing  
│── result.xml                 # XML report for test results  
│── SI_function.py             # Custom function for testing  
│── test_compare.py            # Test cases for comparison operations  
│── test_div_by_3_6.py         # Test cases for division by 3 & 6  
│── test_div_by_11_22.py       # Test cases for division by 11 & 22  
│── test_div_by_13.py          # Test cases for division by 13  
│── test_div_by_44.py          # Test cases for division by 44  
│── test_failure.py            # Test case to simulate failures  
│── test_multiplication.py     # Test cases for multiplication  
│── test_square.py             # Test cases for square calculations


---

Pytest Execution Guide

Below are various ways to run the test cases:

1. Running All Tests

pytest -v

2. Running a Specific Test File

pytest test_div_by_44.py -v

3. Running Tests by Substring Matching

pytest -k "square" -v

4. Running Tests Based on Markers

pytest -m marker_name -v

5. Creating and Using Fixtures

Fixtures are defined in conftest.py and can be used as:

@pytest.fixture
def sample_fixture():
    return "Sample Data"

6. Skipping and Expected Failures

@pytest.mark.skip
def test_to_skip():
    assert False  # This test will be skipped

@pytest.mark.xfail
def test_expected_failure():
    assert False  # This test is expected to fail

7. Stopping Execution on Failure

pytest --maxfail=2 -v

8. Running Tests in Parallel

pytest -n 4 -v  # Runs tests in 4 parallel threads

9. Generating XML Test Report

pytest -v --junitxml="result.xml"


---

Git and GitHub Integration

All test scripts have been versioned using Git and pushed to GitHub using the following workflow:

1. Initialize Git in the Project Directory

git init

2. Add and Commit Changes

git add .
git commit -m "Added Pytest automation scripts"

3. Connect to GitHub Repository

git remote add origin <your-repo-url>

4. Push Changes to GitHub

git push -u origin main


---

Conclusion

This repository serves as a structured guide for using Pytest for automated testing while incorporating Git and GitHub for version control. The provided test cases demonstrate key functionalities such as fixtures, parameterization, skipping tests, failure handling, and parallel execution.
